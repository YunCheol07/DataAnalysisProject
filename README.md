# SKALA 데이터 분석 미니 프로젝트

# 📊 화합물 독성 예측 모델 발표자료

***

## 🎯 프로젝트 개요

### 목표
- **화합물 독성 예측 모델** 개발 (SMILES 기반)
- **F1 Score 0.832+** 달성
- **높은 Recall** 유지 (88.35%)

### 실제 달성 결과
```
✅ F1 Score: 0.8321 (목표 0.8308 대비 +0.13%p)
✅ AUC Score: 0.8953
✅ Recall: 0.8835 (민감도 우선)
```

***

## 📌 전체 파이프라인

```
원본 데이터 (8,349개) 
    ↓
Top 300 피처 + RDKit 48개
    ↓
5-Fold Cross-Validation
    ↓
3개 Base Models (LGBM, XGB, CatBoost)
    ↓
Meta-Learner (LightGBM) + 13개 Meta-features
    ↓
적응형 임계값 (Confidence 기반)
    ↓
최종 예측 (927개 Test)
```

***

## 📊 데이터 구성

### Train/Test 분할

| 구분 | 샘플 수 | Class 0 (무독성) | Class 1 (독성) | 비율 |
|------|---------|------------------|----------------|------|
| **Train** | 8,349 | 3,807 (45.6%) | 4,542 (54.4%) | 1.19:1 |
| **Test** | 927 | ? | ? | - |

**특징**: 약간의 클래스 불균형 (독성 샘플이 9% 많음)

***

## 🔬 Step 1: 피처 엔지니어링

### 1.1 Top 300 기본 피처

```python
# 사전 선별된 중요 피처 300개
├─ Fingerprint (296개): ECFP, FCFP, PTFP 등
└─ Descriptor (4개): MolWt, clogp, sa_score, qed
```

***

### 1.2 RDKit Descriptor 48개 추가

#### 생성 결과
- **총 컬럼**: 48개 (목표 50개 중 2개 누락)
- **성공률**: 97.9% (47개 완벽 생성, 1개 완전 실패)
- **처리 시간**: Train 50.30초, Test 4.97초

#### 실패 컬럼 분석
```python
완전 실패 (100% 결측):
  - rdkit_NumHeteroatoms  # Lipinski 규칙의 헤테로원자 개수
  → Median imputation으로 대체
```

***

### 1.3 RDKit Descriptor 통계 (상위 10개)

| Descriptor | Mean | Std | Min | Max | 해석 |
|-----------|------|-----|-----|-----|------|
| **NumHDonors** | 1.31 | 1.10 | 0 | 18 | 수소결합 공여체 (평균 1.3개) |
| **NumHAcceptors** | 5.64 | 2.17 | 0 | 17 | 수소결합 수용체 (평균 5.6개) |
| **NumRotatableBonds** | 5.74 | 2.40 | 0 | 32 | 회전 가능 결합 (유연성) |
| **RingCount** | 4.29 | 1.20 | 0 | 9 | 고리 개수 (평균 4.3개) |
| **TPSA** | 78.31 | 32.28 | 0 | 496.68 | 극성 표면적 (세포막 투과성) |
| **LabuteASA** | 185.55 | 35.92 | 41.99 | 513.21 | 표면적 |
| **NumAromaticRings** | 2.75 | 1.02 | 0 | 7 | 방향족 고리 (안정성) |

**독성과의 관계**
- 높은 TPSA → 세포막 투과 어려움 → 독성 낮음
- 많은 방향족 고리 → 구조 안정 → 대사 느림 → 독성 축적 가능

***

### 1.4 최종 피처 구성

```python
총 348개 피처 = Top 300 + RDKit 48

[피처 타입별 분류]
  ├─ Fingerprint: 296개 (85.1%)
  ├─ Descriptor (원본): 4개 (1.1%)
  └─ RDKit Descriptor: 48개 (13.8%)
```

***

## 🤖 Step 2: Layer 1 - Base Models (5-Fold CV)

### 모델 구성

| 모델 | n_estimators | learning_rate | max_depth | 주요 특징 |
|------|--------------|---------------|-----------|----------|
| **LightGBM** | 1000 | 0.03 | 8 | Leaf-wise, class_weight={0:1.5, 1:1.0} |
| **XGBoost** | 1000 | 0.03 | 7 | Level-wise, scale_pos_weight=0.67 |
| **CatBoost** | 1000 | 0.03 | 7 | Ordered boosting, class_weights=[1.5, 1.0] |

***

### Fold별 성능 (Valid F1)

| Fold | LGBM | XGB | CatBoost | Early Stop (LGBM) | 소요시간 |
|------|------|-----|----------|-------------------|----------|
| **1** | 0.8323 | 0.8313 | 0.8225 | 727회 | 67.01초 |
| **2** | 0.8020 | 0.8061 | 0.7982 | 474회 | 58.63초 |
| **3** | 0.7937 | 0.7908 | 0.7864 | 434회 | 56.40초 |
| **4** | 0.8117 | 0.8144 | 0.8184 | 510회 | 60.38초 |
| **5** | 0.8231 | 0.8327 | 0.8324 | 582회 | 62.29초 |
| **평균** | **0.8126** | **0.8151** | **0.8116** | 545회 | 60.94초 |

**관찰 포인트**
- Fold 1: 가장 높은 성능 (0.83+)
- Fold 2-3: 성능 하락 (0.79~0.80) → 데이터 분포 차이
- Fold 4-5: 회복 (0.81~0.83)
- **XGBoost가 가장 안정적** (평균 0.8151)

***

### OOF 확률 분포

```python
lgbm    : Mean=0.5130, Std=0.3480, Min=0.0013, Max=0.9996
xgb     : Mean=0.5145, Std=0.3506, Min=0.0013, Max=0.9993
catboost: Mean=0.5084, Std=0.3301, Min=0.0032, Max=0.9994
```

**해석**
- 평균 0.51: 독성/무독성 비율(54:46)과 유사
- Std 0.33 ~ 0.35: 충분한 변별력 (0 ~ 1 전체 활용)
- Min/Max: 극단값 존재 (확신 있는 예측)

***

## 🧠 Step 3: Layer 2 - Meta-Learner

### Meta-Features 13개 구성

```python
1. 기본 확률 (3개)
   - P_lgbm, P_xgb, P_catboost

2. 상호작용 (3개)
   - P_lgbm × P_xgb         # 두 모델 합의도
   - P_xgb × P_catboost
   - P_lgbm × P_catboost

3. 불일치도 (3개)
   - |P_lgbm - P_xgb|       # 예측 차이 (불확실성)
   - |P_xgb - P_catboost|
   - |P_lgbm - P_catboost|

4. 앙상블 통계 (4개)
   - max(3 models)          # 가장 높은 확신
   - min(3 models)          # 가장 낮은 확신
   - mean(3 models)         # 평균 합의
   - std(3 models)          # 의견 분산도
```

***

### Meta-Learner 설정

```python
LGBMClassifier(
    n_estimators=100,      # 빠른 학습
    learning_rate=0.05,
    max_depth=3,           # 얕은 트리 (과적합 방지)
    num_leaves=7,
    class_weight='balanced'
)

학습 시간: 0.08초 (매우 빠름)
```

***

## 🎯 Step 4: 적응형 임계값 전략

### Confidence 기반 동적 조정

```python
confidence = |P - 0.5|  # 0.5에서 멀수록 확신

if confidence < 0.05:      # 매우 불확실 (P ≈ 0.45~0.55)
    threshold = 0.42       # 보수적
elif confidence < 0.10:    # 중간 불확실
    threshold = 0.40
else:                      # 확실함 (P < 0.4 or P > 0.6)
    threshold = 0.39       # 공격적
```

***

### 실제 적용 결과 (Train 8,349개)

| Threshold | 샘플 수 | 비율 | 전략 |
|-----------|---------|------|------|
| **0.42** | 713개 | 8.54% | FPR 최소화 (불확실 샘플) |
| **0.40** | 387개 | 4.64% | 균형 |
| **0.39** | 7,249개 | 86.82% | Recall 향상 (확실 샘플) |

**핵심**
- 86.8%는 확실하게 예측 (낮은 임계값)
- 13.2%는 신중하게 예측 (높은 임계값)

***

## 📊 Step 5: 최종 성능 평가 (OOF)

### 핵심 지표

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  F1 Score:   0.8321  ✅ (목표 0.835 근접)
  AUC Score:  0.8953  ✅ (우수)
  Precision:  0.7864  
  Recall:     0.8835  ✅ (높은 민감도)
  FPR:       28.63%   ⚠️ (목표 대비 높음)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

***

### 혼동 행렬 분석

```
              실제
          무독성   독성
예측  무독성  2,717   1,090  ← FP (Type I Error)
      독성     529   4,013  ← TP (정확히 독성 예측)
```

| 지표 | 값 | 설명 |
|------|-----|------|
| **TN** | 2,717 | 정확히 무독성 예측 (71.3%) |
| **FP** | 1,090 | 독성인데 무독성으로 오판 (28.6%) |
| **FN** | 529 | 무독성인데 독성으로 오판 (11.6%) |
| **TP** | 4,013 | 정확히 독성 예측 (88.4%) |

**핵심 문제**
- **FPR 28.63%**: 무독성 3,807개 중 1,090개를 독성으로 오판
- 목표 3~5%와 큰 차이 → **적응형 임계값이 예상대로 작동 안함**

***

### 성능 비교

| 모델 | F1 Score | 개선폭 | 주요 변화 |
|------|----------|--------|----------|
| 독립 RDKit 9개 (이전 최고) | 0.8308 | - | - |
| **Top 300 + RDKit 48 + Stacking** | **0.8321** | **+0.13%p** | ✅ 신기록 |

***

### 왜 FPR이 높은가?

#### 1. 적응형 임계값 문제
```python
# 실제 적용
Threshold 0.39: 86.82% (대부분 낮은 임계값)
→ Recall 우선 전략으로 작동
→ FP 증가 (무독성을 독성으로 오판)
```

#### 2. 클래스 가중치
```python
class_weight = {0: 1.5, 1: 1.0}
→ Class 0 (무독성)에 1.5배 패널티
→ 무독성 예측을 신중하게 (독성 쪽으로 편향)
```

#### 3. Stacking의 Recall 편향
```python
Meta-features에 min, mean 포함
→ 가장 낮은 확률도 고려
→ 보수적 판단 (독성으로 분류 경향)
```

***

## 📈 Test 예측 결과

### 예측 분포 (927개)

```
Class 0 (무독성): 366개 (39.48%)
Class 1 (독성):   561개 (60.52%)
```

**Train 비율과 비교**
- Train: 45.6% vs 54.4%
- Test: 39.5% vs 60.5%
- → Test에서 독성 비율이 약간 높게 예측됨

---

### 확률 및 Confidence 분석

```python
평균 확률: 0.5144
평균 Confidence: 0.2931
Low Confidence (<0.1): 123개 (13.3%)
```

**해석**
- 평균 확률 0.51: Train과 유사 (일관성 ✓)
- Low Confidence 13.3%: Train(13.2%)과 거의 동일
- → **모델이 안정적으로 작동** 중

***

## 🔍 심층 분석

### Fold별 성능 변동 원인

#### Fold 1 (F1 0.83)
- 가장 높은 성능
- 데이터 분포가 전체와 유사

#### Fold 2-3 (F1 0.79~0.80)
- 성능 하락
- **가능 원인**: Validation set에 어려운 샘플 집중
- Early Stop이 빠름 (434~474회)

#### Fold 4-5 (F1 0.81~0.83)
- 회복
- 균형잡힌 분포

**교훈**: 5-Fold CV로 데이터 변동성 포착 성공

***

### RDKit 효과 분석

| 단계 | F1 | 피처 수 | 개선 메커니즘 |
|------|-----|---------|--------------|
| Top 300만 | 0.8200 | 300 | 기본 지문 |
| + RDKit 9개 | 0.8308 | 309 | +1.08%p (화학 특성 추가) |
| + RDKit 48개 | 0.8321 | 348 | +0.13%p (심화 특성) |

**한계점**
- RDKit 9→48개로 확장했지만 성능 개선 미미 (+0.13%p)
- **가능 원인**: 
  - 추가 descriptor들이 상관관계 높음 (정보 중복)
  - 모델이 이미 포화 상태
  - 1개 컬럼 누락 (NumHeteroatoms)

***

## 💡 핵심 성공 요인

### 1. 안정적인 5-Fold CV
```
15개 독립 모델 (3 × 5) 
→ 데이터 변동성 흡수
→ 평균 F1 0.81~0.82 유지
```

### 2. 다양한 알고리즘
- LightGBM: 빠름, Leaf-wise
- XGBoost: 안정적, Level-wise  
- CatBoost: 범주형 처리 우수

### 3. Meta-Learner의 지능형 결합
- 13개 Meta-features로 모델 간 패턴 학습
- 불일치도 포착으로 불확실성 관리

### 4. 화학 도메인 지식
- RDKit 48개로 독성 메커니즘 반영
- TPSA, 방향족 고리 등 전문 지식 수치화

***

## ⚠️ 개선 필요 사항

### 1. FPR 문제 해결

**현재**: 28.63% (목표: 3~5%)

**해결 방안**
```python
# 1. 임계값 재조정
if confidence < 0.05:
    threshold = 0.55  # 0.42 → 0.55 (더 보수적)

# 2. Class Weight 조정
class_weight = {0: 2.0, 1: 1.0}  # 1.5 → 2.0

# 3. Precision 중심 Metric
- F1 대신 F-beta (β=0.5) 사용
- Precision 가중치 증가
```

***

### 2. RDKit Descriptor 최적화

**문제**: 48개 중 실제 기여도 낮은 descriptor 존재

**해결 방안**
```python
# Feature Importance 분석
importance = meta_model.feature_importances_
top_rdkit = select_top_k(rdkit_features, k=20)

# 상관관계 높은 피처 제거
correlation_matrix = rdkit_df.corr()
remove_high_corr(threshold=0.95)
```

***

### 3. Fold 간 성능 편차 감소

**문제**: Fold 2-3에서 F1 0.79로 하락

**해결 방안**
```python
# Stratified Group K-Fold
- SMILES 유사도로 그룹핑
- 유사한 분자가 같은 Fold에 포함

# 10-Fold로 증가
- 더 많은 학습 데이터
- Validation 안정성 향상
```

***

## 🎯 결론

### 달성 목표 ✅

```
✅ F1 Score 0.8321 (이전 최고 0.8308 초과)
✅ AUC Score 0.8953 (우수한 분류 성능)
✅ Recall 0.8835 (민감도 우선 전략 성공)
⚠️ FPR 28.63% (목표 미달, 개선 필요)
```

***

### 핵심 메시지

> **"화학 도메인 지식 + 5-Fold 앙상블 + Meta-Learning"**  
> = **안정적이고 재현 가능한 독성 예측 모델**

**강점**
- 높은 Recall (88.4%): 독성 물질 잘 포착
- 일관성: Train/Test 확률 분포 유사
- 해석 가능: RDKit descriptor로 화학적 근거 제공

**약점**
- 높은 FPR: 무독성을 독성으로 오판 (28.6%)
- 개선 여지: 임계값 최적화 필요

***

### 활용 방안

#### 1. 신약 개발 초기 스크리닝
```
Recall 88.4% → 독성 물질 놓칠 확률 11.6%
→ 안전성 우선 전략에 적합
```

#### 2. 화학물질 안전성 평가
```
FPR 28.6% → 추가 실험 필요
→ 1차 필터링 도구로 활용
```

#### 3. 규제 기관 참고 자료
```
AUC 0.8953 → 높은 변별력
→ 의사결정 보조 시스템
```

***

## 📁 최종 제출

```bash
submission_ultimate.csv
├─ SMILES: 927개 분자 구조
└─ output: 독성 예측 (0=무독성 366개, 1=독성 561개)

예상 성능: F1 0.83+ (리더보드 확인 필요)
```

***

## 🙋 Q&A

### Q1. FPR이 28.6%로 높은데 실전에서 사용 가능한가요?
A: **Recall 88.4%를 우선**하는 모델입니다. 독성 물질을 놓치면 안 되는 상황(신약 개발)에서는 FPR을 감수하고 사용할 수 있습니다. 추가 실험으로 오탐 줄이는 2단계 프로세스 권장합니다.

### Q2. RDKit 48개 대신 9개만 써도 성능 비슷한가요?
A: 네, RDKit 9개(F1 0.8308)와 48개(F1 0.8321) 차이가 **0.13%p**로 미미합니다. **간단함을 원하면 9개 사용 권장**합니다.

### Q3. 왜 Fold 2-3에서 성능이 떨어졌나요?
A: Validation set에 **어려운 샘플**이 집중되었을 가능성이 높습니다. 5-Fold CV로 이런 변동성을 평균화하여 **최종 모델은 안정적**입니다.

### Q4. Test 결과 561개(60.5%)가 독성인데 너무 많지 않나요?
A: Train에서도 54.4%가 독성이었고, Recall 88.4%를 고려하면 **합리적인 분포**입니다. 실제 Test label로 검증이 필요합니다.

***

**감사합니다!** 🎉

## 화합물 독성 예측 모델 EDA 작업 링크
https://www.notion.so/SKALA-28f315ca9426806aa651f41504790926?source=copy_link

## 경연 결과 (4반 2등, SK 사내 구성원 경연기준 상위 5% 이내)
<img width="1304" height="56" alt="image" src="https://github.com/user-attachments/assets/ee421224-1c3d-4a9d-b69d-3bd6d8800249" />

## 프로젝트 진행 후 소감 (10/20)
- SKALA에서 배운 기초 통계와 데이터 분석을 활용하여 모델을 만들어봤다. 최종으로 제출한 스코어(0.843)의 경우, LLM의 도움이 없었다면 실질적으로 불가능 했을 것이다.
- 지금 내가 가지고 있는 능력에서 최대치는 아마도 처음에 제출했던 스코어 점수인 0.831이 최대일 것이다. 2차를 거쳐 최종 제출까지 변경된 코드에 대해서 내 자신이 이해하면서 만들었다는 생각이 들진 않는다.
- 내가 제출한 모델에 대해서 내가 정확히 잘 알지 못하는 상태에서 스코어가 높은 것은 마냥 좋은 것만은 아니라고 생각했다. 사실상 내가 만든게 아니라 클로드가 만들어준 것이니깐
- 일단 내가 만든 모델에 대해서 제대로 이해하기 위해 얄 안전성 우선 전략에 적합
```

#### 2. 화학물질 안전성 평가
```
FPR 28.6% → 추가 실험 필요
→ 1차 필터링 도구로 활용
```

#### 3. 규제 기관 참고 자료
```
AUC 0.8953 → 높은 변별력
→ 의사결정 보조 시스템
```

***

## 📁 최종 제출

```bash
submission_ultimate.csv
├─ SMILES: 927개 분자 구조
└─ output: 독성 예측 (0=무독성 366개, 1=독성 561개)

예상 성능: F1 0.83+ (리더보드 확인 필요)
```

***

## 🙋 Q&A

### Q1. FPR이 28.6%로 높은데 실전에서 사용 가능한가요?
A: **Recall 88.4%를 우선**하는 모델입니다. 독성 물질을 놓치면 안 되는 상황(신약 개발)에서는 FPR을 감수하고 사용할 수 있습니다. 추가 실험으로 오탐 줄이는 2단계 프로세스 권장합니다.

### Q2. RDKit 48개 대신 9개만 써도 성능 비슷한가요?
A: 네, RDKit 9개(F1 0.8308)와 48개(F1 0.8321) 차이가 **0.13%p**로 미미합니다. **간단함을 원하면 9개 사용 권장**합니다.

### Q3. 왜 Fold 2-3에서 성능이 떨어졌나요?
A: Validation set에 **어려운 샘플**이 집중되었을 가능성이 높습니다. 5-Fold CV로 이런 변동성을 평균화하여 **최종 모델은 안정적**입니다.

### Q4. Test 결과 561개(60.5%)가 독성인데 너무 많지 않나요?
A: Train에서도 54.4%가 독성이었고, Recall 88.4%를 고려하면 **합리적인 분포**입니다. 실제 Test label로 검증이 필요합니다.

***

**감사합니다!** 🎉

## 화합물 독성 예측 모델 EDA 작업 링크
https://www.notion.so/SKALA-28f315ca9426806aa651f41504790926?source=copy_link

## 경연 결과 (4반 2등, SK 사내 구성원 경연기준 상위 5% 이내)
<img width="1304" height="56" alt="image" src="https://github.com/user-attachments/assets/ee421224-1c3d-4a9d-b69d-3bd6d8800249" />

## 프로젝트 진행 후 소감 (10/20)
- SKALA에서 배운 기초 통계와 데이터 분석을 활용하여 모델을 만들어봤다. 최종으로 제출한 스코어(0.843)의 경우, LLM의 도움이 없었다면 실질적으로 불가능 했을 것이다.
- 지금 내가 가지고 있는 능력에서 최대치는 아마도 처음에 제출했던 스코어 점수인 0.831이 최대일 것이다. 2차를 거쳐 최종 제출까지 변경된 코드에 대해서 내 자신이 완벽히 이해하면서 만들었다는 생각이 들진 않는다.
- 내가 제출한 모델에 대해서 내가 정확히 잘 알지 못하는 상태에서 스코어가 높은 것은 마냥 좋은 것만은 아니라고 생각했다. 사실상 내가 만든게 아니라 클로드가 만들어준 것이니까.
- 내가 만든 모델에 대해서 제대로 이해하기 위해 얇게 파악하고 있던 기초 모델 지식(LGBM, XGBoost 등)과 기초 통계에 대해 다시 공부하면서 모델을 왜 이렇게 만들었는지 이해해야
  나중에 프로젝트가 됐건 회사에 입사해서 실전에서 모델링을 할 때 고객들을 설득할 때 설득력이 더 생길 뿐만 아니라 모델링 하는 방법이 지금보단 능숙해져 더 잘 만들 수 있을 것이라고 생각한다.
 
