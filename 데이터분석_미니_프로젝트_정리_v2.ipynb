{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRGVckX96DL-",
        "outputId": "8d5f185b-342a-4746-ebf8-188ae49c98b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "단계 1: 데이터 적재 및 전처리 파이프라인\n",
            "======================================================================\n",
            "\n",
            "데이터 크기: (8349, 3078)\n",
            "컬럼 수: 3078\n",
            "\n",
            "데이터 타입:\n",
            "int64      3073\n",
            "float64       4\n",
            "object        1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "결측치 확인:\n",
            "전체 결측치: 0개\n",
            "\n",
            "라벨 분포:\n",
            "label\n",
            "1    0.544017\n",
            "0    0.455983\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Fingerprint 컬럼: 3072개\n",
            "물성 컬럼: ['MolWt', 'clogp', 'sa_score', 'qed']\n",
            "\n",
            "전처리 파이프라인 구축 완료\n",
            "  - Fingerprint: 결측 → 0 대치\n",
            "  - 물성: 결측 → 중앙값 대치 + StandardScaler\n",
            "  - 교차검증: 5-Fold Stratified\n",
            "\n",
            "Fold 1: 학습 (6679, 3076), 검증 (1670, 3076)\n",
            "\n",
            "✓ 단계 1 완료\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 단계 1: 데이터 적재 및 전처리 파이프라인 구축\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"단계 1: 데이터 적재 및 전처리 파이프라인\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 1.1 데이터 로드\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "print(f\"\\n데이터 크기: {df.shape}\")\n",
        "print(f\"컬럼 수: {len(df.columns)}\")\n",
        "\n",
        "# 1.2 기본 정보 확인\n",
        "print(f\"\\n데이터 타입:\")\n",
        "print(df.dtypes.value_counts())\n",
        "\n",
        "print(f\"\\n결측치 확인:\")\n",
        "print(f\"전체 결측치: {df.isna().sum().sum()}개\")\n",
        "\n",
        "print(f\"\\n라벨 분포:\")\n",
        "print(df['label'].value_counts(normalize=True))\n",
        "\n",
        "# 1.3 컬럼 그룹 정의\n",
        "fp_cols = [col for col in df.columns if col.startswith(('ecfp_', 'fcfp_', 'ptfp_'))]\n",
        "desc_cols = ['MolWt', 'clogp', 'sa_score', 'qed']\n",
        "id_col = 'SMILES'\n",
        "label_col = 'label'\n",
        "\n",
        "print(f\"\\nFingerprint 컬럼: {len(fp_cols)}개\")\n",
        "print(f\"물성 컬럼: {desc_cols}\")\n",
        "\n",
        "# 1.4 X, y 분리\n",
        "X = df.drop(columns=[label_col])\n",
        "y = df[label_col].astype(int)\n",
        "\n",
        "# 1.5 전처리 파이프라인 구성\n",
        "fp_transformer = SimpleImputer(strategy='constant', fill_value=0)\n",
        "# - 목적: Fingerprint는 0/1 값을 가지는 binary 특성이므로\n",
        "#         결측치를 0으로 대치 (분자 구조에 해당 substructure 없음을 의미)\n",
        "# - strategy='constant': 고정된 상수값으로 채움\n",
        "# - fill_value=0: 결측치를 모두 0으로 대치\n",
        "\n",
        "desc_transformer = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')), # 1단계: 중앙값 대치\n",
        "    # - 1단계: 결측치 처리\n",
        "    # - strategy='median': 각 컬럼의 중앙값으로 결측치 대치\n",
        "    # - 평균 대신 중앙값 사용 이유: 이상치(outlier)의 영향을 덜 받음\n",
        "    ('scaler', StandardScaler()) # 2단계: 표준화\n",
        "    # - 2단계: 특성 스케일링 (표준화)\n",
        "    # - 각 컬럼을 평균 0, 표준편차 1로 변환\n",
        "    # - 공식: z = (x - μ) / σ\n",
        "    # - 이유: MolWt(분자량), clogP, sa_score, qed는\n",
        "    #         서로 다른 스케일을 가지므로 정규화 필요\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('fp', fp_transformer, fp_cols),\n",
        "        ('desc', desc_transformer, desc_cols)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# 1.6 교차검증 분할 테스트\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(f\"\\n전처리 파이프라인 구축 완료\")\n",
        "print(f\"  - Fingerprint: 결측 → 0 대치\")\n",
        "print(f\"  - 물성: 결측 → 중앙값 대치 + StandardScaler\")\n",
        "print(f\"  - 교차검증: 5-Fold Stratified\")\n",
        "\n",
        "# 1.7 샘플 변환 테스트\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
        "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
        "\n",
        "    Xt_tr = preprocessor.fit_transform(X_tr)\n",
        "    Xt_va = preprocessor.transform(X_va)\n",
        "\n",
        "    print(f\"\\nFold {fold}: 학습 {Xt_tr.shape}, 검증 {Xt_va.shape}\")\n",
        "    break  # 첫 fold만 확인\n",
        "\n",
        "print(\"\\n✓ 단계 1 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"단계 2: 베이스라인 모델 학습 (개선)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "f1_scores = []\n",
        "models = []\n",
        "\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
        "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
        "\n",
        "    # 전처리\n",
        "    Xt_tr = preprocessor.fit_transform(X_tr)\n",
        "    Xt_va = preprocessor.transform(X_va)\n",
        "\n",
        "    # 모델 학습 (개선된 파라미터)\n",
        "    model = LGBMClassifier(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=7,\n",
        "        num_leaves=31,\n",
        "        min_child_samples=20,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_alpha=1.0,\n",
        "        reg_lambda=1.0,\n",
        "        class_weight='balanced',\n",
        "        random_state=RANDOM_STATE,\n",
        "        verbose=-1\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        Xt_tr, y_tr,\n",
        "        eval_set=[(Xt_va, y_va)],\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
        "    )\n",
        "\n",
        "    models.append(model)\n",
        "\n",
        "    # 예측 및 평가\n",
        "    y_pred = model.predict(Xt_va)\n",
        "    f1 = f1_score(y_va, y_pred)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"\\n[Fold {fold}]\")\n",
        "    print(f\"  학습: {Xt_tr.shape}, 검증: {Xt_va.shape}\")\n",
        "    print(f\"  최적 Iteration: {model.best_iteration_}\")\n",
        "    print(f\"  F1 Score: {f1:.4f}\")\n",
        "    print(f\"  분류 리포트:\")\n",
        "    print(classification_report(y_va, y_pred,\n",
        "                                target_names=['독성 有(0)', '독성 無(1)']))\n",
        "    print(f\"  혼동 행렬:\")\n",
        "    print(confusion_matrix(y_va, y_pred))\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"베이스라인 평균 F1 Score: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n",
        "print(f\"Fold별 F1: {[f'{f:.4f}' for f in f1_scores]}\")\n",
        "print(\"\\n✓ 단계 2 완료\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ0wIl9r_jla",
        "outputId": "0e5c3588-e8a0-4290-fb2b-96e58404c2ff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "단계 2: 베이스라인 모델 학습 (개선)\n",
            "======================================================================\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\tvalid_0's binary_logloss: 0.406499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Fold 1]\n",
            "  학습: (6679, 3076), 검증: (1670, 3076)\n",
            "  최적 Iteration: 500\n",
            "  F1 Score: 0.8256\n",
            "  분류 리포트:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      비활성(0)       0.79      0.81      0.80       761\n",
            "       활성(1)       0.83      0.82      0.83       909\n",
            "\n",
            "    accuracy                           0.81      1670\n",
            "   macro avg       0.81      0.81      0.81      1670\n",
            "weighted avg       0.81      0.81      0.81      1670\n",
            "\n",
            "  혼동 행렬:\n",
            "[[613 148]\n",
            " [166 743]]\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[469]\tvalid_0's binary_logloss: 0.443228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Fold 2]\n",
            "  학습: (6679, 3076), 검증: (1670, 3076)\n",
            "  최적 Iteration: 469\n",
            "  F1 Score: 0.8011\n",
            "  분류 리포트:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      비활성(0)       0.76      0.77      0.76       761\n",
            "       활성(1)       0.80      0.80      0.80       909\n",
            "\n",
            "    accuracy                           0.78      1670\n",
            "   macro avg       0.78      0.78      0.78      1670\n",
            "weighted avg       0.78      0.78      0.78      1670\n",
            "\n",
            "  혼동 행렬:\n",
            "[[585 176]\n",
            " [184 725]]\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[451]\tvalid_0's binary_logloss: 0.460899\n",
            "\n",
            "[Fold 3]\n",
            "  학습: (6679, 3076), 검증: (1670, 3076)\n",
            "  최적 Iteration: 451\n",
            "  F1 Score: 0.7871\n",
            "  분류 리포트:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      비활성(0)       0.74      0.78      0.76       762\n",
            "       활성(1)       0.81      0.77      0.79       908\n",
            "\n",
            "    accuracy                           0.77      1670\n",
            "   macro avg       0.77      0.77      0.77      1670\n",
            "weighted avg       0.78      0.77      0.77      1670\n",
            "\n",
            "  혼동 행렬:\n",
            "[[596 166]\n",
            " [211 697]]\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[498]\tvalid_0's binary_logloss: 0.419175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Fold 4]\n",
            "  학습: (6679, 3076), 검증: (1670, 3076)\n",
            "  최적 Iteration: 498\n",
            "  F1 Score: 0.8233\n",
            "  분류 리포트:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      비활성(0)       0.79      0.78      0.79       762\n",
            "       활성(1)       0.82      0.83      0.82       908\n",
            "\n",
            "    accuracy                           0.81      1670\n",
            "   macro avg       0.81      0.81      0.81      1670\n",
            "weighted avg       0.81      0.81      0.81      1670\n",
            "\n",
            "  혼동 행렬:\n",
            "[[598 164]\n",
            " [158 750]]\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\tvalid_0's binary_logloss: 0.415413\n",
            "\n",
            "[Fold 5]\n",
            "  학습: (6680, 3076), 검증: (1669, 3076)\n",
            "  최적 Iteration: 500\n",
            "  F1 Score: 0.8240\n",
            "  분류 리포트:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      비활성(0)       0.79      0.79      0.79       761\n",
            "       활성(1)       0.82      0.82      0.82       908\n",
            "\n",
            "    accuracy                           0.81      1669\n",
            "   macro avg       0.81      0.81      0.81      1669\n",
            "weighted avg       0.81      0.81      0.81      1669\n",
            "\n",
            "  혼동 행렬:\n",
            "[[600 161]\n",
            " [159 749]]\n",
            "\n",
            "======================================================================\n",
            "베이스라인 평균 F1 Score: 0.8122 ± 0.0154\n",
            "Fold별 F1: ['0.8256', '0.8011', '0.7871', '0.8233', '0.8240']\n",
            "\n",
            "✓ 단계 2 완료\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"단계 3: 특징 중요도 분석 (개선)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 컬럼 그룹 정의\n",
        "fp_cols = [col for col in df.columns if col.startswith(('ecfp_', 'fcfp_', 'ptfp_'))]\n",
        "desc_cols = ['MolWt', 'clogp', 'sa_score', 'qed']\n",
        "label_col = 'label'\n",
        "\n",
        "# ⭐ 중요: feature_names 정의 (전처리 후 순서)\n",
        "feature_names = fp_cols + desc_cols  # Fingerprint 컬럼 + 물성 컬럼\n",
        "\n",
        "print(f\"전체 피처 수: {len(feature_names)}개\")\n",
        "print(f\"  - Fingerprint: {len(fp_cols)}개\")\n",
        "print(f\"  - 물성: {len(desc_cols)}개\")\n",
        "\n",
        "# X, y 분리\n",
        "X = df.drop(columns=[label_col])\n",
        "y = df[label_col].astype(int)\n",
        "\n",
        "# 전처리 파이프라인\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('fp', SimpleImputer(strategy='constant', fill_value=0), fp_cols),\n",
        "        ('desc', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), desc_cols)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# 교차검증 설정\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# CV 기반 중요도 계산\n",
        "fold_importances = []\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
        "    X_tr = X.iloc[tr_idx]\n",
        "    y_tr = y.iloc[tr_idx]\n",
        "\n",
        "    Xt_tr = preprocessor.fit_transform(X_tr)\n",
        "\n",
        "    model = LGBMClassifier(\n",
        "        n_estimators=500, learning_rate=0.05, max_depth=7,\n",
        "        num_leaves=31, class_weight='balanced',\n",
        "        random_state=42, verbose=-1\n",
        "    )\n",
        "    model.fit(Xt_tr, y_tr)\n",
        "\n",
        "    # Gain 기반 중요도\n",
        "    importances = model.booster_.feature_importance(importance_type='gain')\n",
        "    fold_importances.append(importances)\n",
        "\n",
        "# 통계 계산\n",
        "importance_mean = np.mean(fold_importances, axis=0)\n",
        "importance_std = np.std(fold_importances, axis=0)\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance_mean': importance_mean,\n",
        "    'importance_std': importance_std\n",
        "}).sort_values('importance_mean', ascending=False)\n",
        "\n",
        "print(\"\\n=== 상위 20개 중요 피처 (Gain 기반) ===\")\n",
        "print(importance_df.head(20).to_string(index=False))\n",
        "\n",
        "# 물성 피처 분석\n",
        "print(\"\\n=== 물성 피처 중요도 ===\")\n",
        "desc_importance = importance_df[importance_df['feature'].isin(desc_cols)]\n",
        "print(desc_importance.to_string(index=False))\n",
        "\n",
        "# 저중요도 피처 필터링\n",
        "threshold = importance_df['importance_mean'].sum() * 0.01\n",
        "selected_features = importance_df[importance_df['importance_mean'] >= threshold]['feature'].tolist()\n",
        "print(f\"\\n선택된 피처: {len(selected_features)}개 (임계값: {threshold:.2f})\")\n",
        "\n",
        "# 시각화\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "top20 = importance_df.head(20)\n",
        "ax.barh(range(len(top20)), top20['importance_mean'])\n",
        "ax.set_yticks(range(len(top20)))\n",
        "ax.set_yticklabels(top20['feature'])\n",
        "ax.invert_yaxis()\n",
        "ax.set_xlabel('Importance (Gain)')\n",
        "ax.set_title('Top 20 Feature Importance')\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_importance_top20.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# CSV 저장\n",
        "importance_df.to_csv('feature_importance_cv.csv', index=False)\n",
        "print(\"\\n✓ 특징 중요도 저장: feature_importance_cv.csv\")\n",
        "print(\"✓ 시각화 저장: feature_importance_top20.png\")\n",
        "print(\"✓ 단계 3 완료\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96ZPkKmWAVH-",
        "outputId": "551ee6c4-8a74-42e3-8b80-4325aab56523"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "단계 3: 특징 중요도 분석 (개선)\n",
            "======================================================================\n",
            "전체 피처 수: 3076개\n",
            "  - Fingerprint: 3072개\n",
            "  - 물성: 4개\n",
            "\n",
            "=== 상위 20개 중요 피처 (Gain 기반) ===\n",
            "  feature  importance_mean  importance_std\n",
            "    clogp      9086.245138      329.690053\n",
            " ecfp_807      2481.696333      193.827500\n",
            " sa_score      1437.898631       95.288599\n",
            "      qed      1260.252706       66.139287\n",
            " fcfp_926      1254.523910      243.868331\n",
            "  fcfp_18      1140.655177       41.684327\n",
            "    MolWt      1108.381560       97.641585\n",
            " ecfp_887       554.562280      127.046617\n",
            " ecfp_219       502.327773      155.912626\n",
            " ecfp_767       491.163915      239.430468\n",
            " ecfp_893       403.326927      237.587663\n",
            " fcfp_546       394.383086      139.921297\n",
            " fcfp_671       382.294291       77.640999\n",
            " fcfp_370       343.620895       74.114468\n",
            " ptfp_666       306.139495       53.843023\n",
            "ptfp_1013       295.335594       78.396048\n",
            " ptfp_596       265.862897       51.307877\n",
            "fcfp_1008       263.407184       53.722803\n",
            " ptfp_281       222.196898       94.925660\n",
            " fcfp_968       219.665339       43.071733\n",
            "\n",
            "=== 물성 피처 중요도 ===\n",
            " feature  importance_mean  importance_std\n",
            "   clogp      9086.245138      329.690053\n",
            "sa_score      1437.898631       95.288599\n",
            "     qed      1260.252706       66.139287\n",
            "   MolWt      1108.381560       97.641585\n",
            "\n",
            "선택된 피처: 7개 (임계값: 699.96)\n",
            "\n",
            "✓ 특징 중요도 저장: feature_importance_cv.csv\n",
            "✓ 시각화 저장: feature_importance_top20.png\n",
            "✓ 단계 3 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 단계 4: 피처 선택 + 임계값 최적화 (통합 버전)\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    f1_score, precision_recall_curve, roc_curve,\n",
        "    roc_auc_score, average_precision_score,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "from lightgbm import LGBMClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"단계 4: 피처 선택 기반 임계값 최적화\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# ============================================================\n",
        "# 1. 데이터 로드 및 피처 선택\n",
        "# ============================================================\n",
        "\n",
        "# 특징 중요도 로드\n",
        "importance_df = pd.read_csv('feature_importance_cv.csv')\n",
        "\n",
        "# 상위 150개 피처 선택 (실험적으로 조정 가능: 100~200)\n",
        "TOP_N = 150\n",
        "selected_features = importance_df.head(TOP_N)['feature'].tolist()\n",
        "\n",
        "print(f\"\\n[피처 선택]\")\n",
        "print(f\"  전체 피처: {len(importance_df)}개\")\n",
        "print(f\"  선택된 피처: {len(selected_features)}개\")\n",
        "print(f\"  제거된 피처: {len(importance_df) - len(selected_features)}개\")\n",
        "\n",
        "# 물성 피처 확인\n",
        "desc_cols = ['MolWt', 'clogp', 'sa_score', 'qed']\n",
        "desc_in_selected = [f for f in selected_features if f in desc_cols]\n",
        "print(f\"  선택된 물성 피처: {desc_in_selected}\")\n",
        "\n",
        "# 데이터 로드\n",
        "df = pd.read_csv('train.csv')\n",
        "X = df[selected_features]\n",
        "y = df['label'].astype(int)\n",
        "\n",
        "print(f\"\\n데이터 크기: {X.shape}\")\n",
        "print(f\"레이블 분포: {y.value_counts().to_dict()}\")\n",
        "\n",
        "# ============================================================\n",
        "# 2. 전처리 파이프라인 (선택된 피처 기반)\n",
        "# ============================================================\n",
        "\n",
        "fp_cols_selected = [f for f in selected_features if f.startswith(('ecfp_', 'fcfp_', 'ptfp_'))]\n",
        "desc_cols_selected = [f for f in selected_features if f in desc_cols]\n",
        "\n",
        "print(f\"\\n전처리 대상:\")\n",
        "print(f\"  Fingerprint: {len(fp_cols_selected)}개\")\n",
        "print(f\"  물성: {len(desc_cols_selected)}개\")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('fp', SimpleImputer(strategy='constant', fill_value=0), fp_cols_selected),\n",
        "        ('desc', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), desc_cols_selected)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 3. 교차검증 기반 임계값 최적화\n",
        "# ============================================================\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "f1_scores_baseline = []  # 기본 임계값 (0.5)\n",
        "f1_scores_optimized = []  # 최적화된 임계값\n",
        "best_thresholds = []\n",
        "fold_results = []\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"교차검증 시작\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
        "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
        "\n",
        "    # 전처리\n",
        "    Xt_tr = preprocessor.fit_transform(X_tr)\n",
        "    Xt_va = preprocessor.transform(X_va)\n",
        "\n",
        "    # 모델 학습 (개선된 하이퍼파라미터)\n",
        "    model = LGBMClassifier(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=7,\n",
        "        num_leaves=31,\n",
        "        min_child_samples=20,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_alpha=1.0,\n",
        "        reg_lambda=1.0,\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        verbose=-1\n",
        "    )\n",
        "\n",
        "    model.fit(Xt_tr, y_tr)\n",
        "\n",
        "    # 확률 예측\n",
        "    y_proba = model.predict_proba(Xt_va)[:, 1]\n",
        "\n",
        "    # --------------------------------------------------------\n",
        "    # 3-1. 임계값 그리드 탐색 (F1 최대화)\n",
        "    # --------------------------------------------------------\n",
        "    thresholds_grid = np.linspace(0.1, 0.9, 81)\n",
        "    f1_scores_grid = []\n",
        "\n",
        "    for thresh in thresholds_grid:\n",
        "        y_pred = (y_proba >= thresh).astype(int)\n",
        "        f1_scores_grid.append(f1_score(y_va, y_pred))\n",
        "\n",
        "    best_idx = np.argmax(f1_scores_grid)\n",
        "    best_threshold = thresholds_grid[best_idx]\n",
        "    best_f1 = f1_scores_grid[best_idx]\n",
        "    best_thresholds.append(best_threshold)\n",
        "\n",
        "    # --------------------------------------------------------\n",
        "    # 3-2. 기본 임계값 vs 최적 임계값 비교\n",
        "    # --------------------------------------------------------\n",
        "    y_pred_baseline = (y_proba >= 0.5).astype(int)\n",
        "    y_pred_optimized = (y_proba >= best_threshold).astype(int)\n",
        "\n",
        "    f1_baseline = f1_score(y_va, y_pred_baseline)\n",
        "    f1_optimized = f1_score(y_va, y_pred_optimized)\n",
        "\n",
        "    f1_scores_baseline.append(f1_baseline)\n",
        "    f1_scores_optimized.append(f1_optimized)\n",
        "\n",
        "    # --------------------------------------------------------\n",
        "    # 3-3. 추가 메트릭 계산\n",
        "    # --------------------------------------------------------\n",
        "    roc_auc = roc_auc_score(y_va, y_proba)\n",
        "    pr_auc = average_precision_score(y_va, y_proba)\n",
        "\n",
        "    # Confidence 분석\n",
        "    confidence = np.abs(y_proba - 0.5)\n",
        "    low_confidence_count = (confidence < 0.1).sum()\n",
        "    avg_confidence = confidence.mean()\n",
        "\n",
        "    # --------------------------------------------------------\n",
        "    # 3-4. 결과 출력\n",
        "    # --------------------------------------------------------\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"[Fold {fold}]\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"피처: {len(selected_features)}개 사용\")\n",
        "    print(f\"학습 데이터: {Xt_tr.shape}, 검증 데이터: {Xt_va.shape}\")\n",
        "    print(f\"\\n[성능 비교]\")\n",
        "    print(f\"  기본 임계값 (0.50): F1 = {f1_baseline:.4f}\")\n",
        "    print(f\"  최적 임계값 ({best_threshold:.3f}): F1 = {f1_optimized:.4f}\")\n",
        "    print(f\"  개선량: {f1_optimized - f1_baseline:+.4f}\")\n",
        "    print(f\"\\n[추가 메트릭]\")\n",
        "    print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
        "    print(f\"  PR-AUC: {pr_auc:.4f}\")\n",
        "    print(f\"  평균 Confidence: {avg_confidence:.4f}\")\n",
        "    print(f\"  낮은 Confidence (<0.1): {low_confidence_count}개 ({low_confidence_count/len(y_va)*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\n[혼동행렬 - 최적 임계값]\")\n",
        "    cm = confusion_matrix(y_va, y_pred_optimized)\n",
        "    print(cm)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    print(f\"  TN={tn}, FP={fp}, FN={fn}, TP={tp}\")\n",
        "    print(f\"  FPR={fp/(fp+tn):.3f}, FNR={fn/(fn+tp):.3f}\")\n",
        "\n",
        "    print(f\"\\n[분류 리포트 - 최적 임계값]\")\n",
        "    print(classification_report(y_va, y_pred_optimized,\n",
        "                                target_names=['비활성(0)', '활성(1)'],\n",
        "                                digits=4))\n",
        "\n",
        "    # 결과 저장\n",
        "    fold_results.append({\n",
        "        'fold': fold,\n",
        "        'threshold': best_threshold,\n",
        "        'f1_baseline': f1_baseline,\n",
        "        'f1_optimized': f1_optimized,\n",
        "        'improvement': f1_optimized - f1_baseline,\n",
        "        'roc_auc': roc_auc,\n",
        "        'pr_auc': pr_auc,\n",
        "        'avg_confidence': avg_confidence,\n",
        "        'low_confidence_pct': low_confidence_count/len(y_va)*100\n",
        "    })\n",
        "\n",
        "    # --------------------------------------------------------\n",
        "    # 3-5. 시각화 (첫 번째 Fold만)\n",
        "    # --------------------------------------------------------\n",
        "    if fold == 1:\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "        # 1) F1 Score vs Threshold\n",
        "        axes[0, 0].plot(thresholds_grid, f1_scores_grid, marker='o', markersize=3)\n",
        "        axes[0, 0].axvline(x=best_threshold, color='r', linestyle='--',\n",
        "                          label=f'Best F1={best_f1:.4f} at {best_threshold:.3f}')\n",
        "        axes[0, 0].axvline(x=0.5, color='gray', linestyle=':', alpha=0.5, label='Default (0.5)')\n",
        "        axes[0, 0].set_xlabel('Threshold')\n",
        "        axes[0, 0].set_ylabel('F1 Score')\n",
        "        axes[0, 0].set_title('F1 Score vs Threshold')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # 2) Precision-Recall Curve\n",
        "        precision, recall, pr_thresholds = precision_recall_curve(y_va, y_proba)\n",
        "        axes[0, 1].plot(recall, precision, marker='.', markersize=2)\n",
        "        axes[0, 1].set_xlabel('Recall')\n",
        "        axes[0, 1].set_ylabel('Precision')\n",
        "        axes[0, 1].set_title(f'Precision-Recall Curve (AP={pr_auc:.4f})')\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # 3) ROC Curve\n",
        "        fpr, tpr, roc_thresholds = roc_curve(y_va, y_proba)\n",
        "        axes[1, 0].plot(fpr, tpr, marker='.', markersize=2)\n",
        "        axes[1, 0].plot([0, 1], [0, 1], 'k--', alpha=0.3, label='Random')\n",
        "        axes[1, 0].set_xlabel('False Positive Rate')\n",
        "        axes[1, 0].set_ylabel('True Positive Rate')\n",
        "        axes[1, 0].set_title(f'ROC Curve (AUC={roc_auc:.4f})')\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # 4) Confidence Distribution\n",
        "        axes[1, 1].hist(confidence, bins=50, edgecolor='black', alpha=0.7)\n",
        "        axes[1, 1].axvline(x=0.1, color='r', linestyle='--',\n",
        "                          label=f'Low Confidence: {low_confidence_count}개')\n",
        "        axes[1, 1].set_xlabel('Confidence (|prob - 0.5|)')\n",
        "        axes[1, 1].set_ylabel('Frequency')\n",
        "        axes[1, 1].set_title('Confidence Distribution')\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('threshold_optimization_analysis.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        print(f\"\\n✓ 시각화 저장: threshold_optimization_analysis.png\")\n",
        "\n",
        "# ============================================================\n",
        "# 4. 최종 통계 및 결과 저장\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"최종 통계\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\\n[피처 선택 효과]\")\n",
        "print(f\"  사용 피처: {len(selected_features)}개\")\n",
        "print(f\"  제거 피처: {len(importance_df) - len(selected_features)}개\")\n",
        "\n",
        "print(f\"\\n[기본 임계값 (0.5)]\")\n",
        "print(f\"  평균 F1: {np.mean(f1_scores_baseline):.4f}\")\n",
        "print(f\"  표준편차: {np.std(f1_scores_baseline):.4f}\")\n",
        "print(f\"  Fold별: {[f'{f:.4f}' for f in f1_scores_baseline]}\")\n",
        "\n",
        "print(f\"\\n[최적화된 임계값]\")\n",
        "print(f\"  평균 F1: {np.mean(f1_scores_optimized):.4f}\")\n",
        "print(f\"  표준편차: {np.std(f1_scores_optimized):.4f}\")\n",
        "print(f\"  Fold별: {[f'{f:.4f}' for f in f1_scores_optimized]}\")\n",
        "\n",
        "print(f\"\\n[임계값 통계]\")\n",
        "print(f\"  평균 임계값: {np.mean(best_thresholds):.3f}\")\n",
        "print(f\"  표준편차: {np.std(best_thresholds):.3f}\")\n",
        "print(f\"  범위: [{np.min(best_thresholds):.3f}, {np.max(best_thresholds):.3f}]\")\n",
        "print(f\"  Fold별: {[f'{t:.3f}' for t in best_thresholds]}\")\n",
        "\n",
        "# 임계값 안정성 평가\n",
        "threshold_cv = np.std(best_thresholds) / (np.mean(best_thresholds) + 1e-10)\n",
        "print(f\"  변동계수: {threshold_cv:.3f}\")\n",
        "\n",
        "if threshold_cv < 0.10:\n",
        "    print(\"  ✓ 임계값이 매우 안정적입니다.\")\n",
        "elif threshold_cv < 0.20:\n",
        "    print(\"  ✓ 임계값이 안정적입니다.\")\n",
        "else:\n",
        "    print(\"  ⚠️ 경고: 임계값 변동이 큽니다. 모델 재검토 필요.\")\n",
        "\n",
        "print(f\"\\n[전체 개선량]\")\n",
        "improvement = np.mean(f1_scores_optimized) - np.mean(f1_scores_baseline)\n",
        "print(f\"  F1 개선: {improvement:+.4f} ({improvement/np.mean(f1_scores_baseline)*100:+.2f}%)\")\n",
        "\n",
        "# 결과 DataFrame 저장\n",
        "results_df = pd.DataFrame(fold_results)\n",
        "results_df.to_csv('threshold_optimization_results_v2.csv', index=False)\n",
        "\n",
        "print(f\"\\n✓ 결과 저장: threshold_optimization_results_v2.csv\")\n",
        "\n",
        "# 최종 권장 임계값\n",
        "optimal_threshold_final = np.mean(best_thresholds)\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"최종 권장 임계값: {optimal_threshold_final:.3f}\")\n",
        "print(f\"이 값을 test 데이터 예측 시 사용하세요.\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "print(\"\\n✓ 단계 4 완료\")\n",
        "\n",
        "# ============================================================\n",
        "# 5. 추가 분석: 이전 제출 결과와 비교\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"이전 제출 결과 비교 (참고)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "try:\n",
        "    submission_old = pd.read_csv('submission_detailed_1.csv')\n",
        "    print(f\"이전 제출:\")\n",
        "    print(f\"  평균 Confidence: {submission_old['confidence'].mean():.4f}\")\n",
        "    print(f\"  낮은 Confidence (<0.1): {(submission_old['confidence'] < 0.1).sum()}개 \"\n",
        "          f\"({(submission_old['confidence'] < 0.1).sum()/len(submission_old)*100:.1f}%)\")\n",
        "    print(f\"\\n개선 기대:\")\n",
        "    print(f\"  평균 Confidence: {np.mean([r['avg_confidence'] for r in fold_results]):.4f}\")\n",
        "    print(f\"  낮은 Confidence (<0.1): 평균 {np.mean([r['low_confidence_pct'] for r in fold_results]):.1f}%\")\n",
        "except FileNotFoundError:\n",
        "    print(\"이전 제출 파일을 찾을 수 없습니다.\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhHVZPYTBI73",
        "outputId": "0c0a3099-c4bd-4467-ba02-bde66ae6e21f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "단계 4: 피처 선택 기반 임계값 최적화\n",
            "======================================================================\n",
            "\n",
            "[피처 선택]\n",
            "  전체 피처: 3076개\n",
            "  선택된 피처: 150개\n",
            "  제거된 피처: 2926개\n",
            "  선택된 물성 피처: ['clogp', 'sa_score', 'qed', 'MolWt']\n",
            "\n",
            "데이터 크기: (8349, 150)\n",
            "레이블 분포: {1: 4542, 0: 3807}\n",
            "\n",
            "전처리 대상:\n",
            "  Fingerprint: 146개\n",
            "  물성: 4개\n",
            "\n",
            "======================================================================\n",
            "교차검증 시작\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "[Fold 1]\n",
            "======================================================================\n",
            "피처: 150개 사용\n",
            "학습 데이터: (6679, 150), 검증 데이터: (1670, 150)\n",
            "\n",
            "[성능 비교]\n",
            "  기본 임계값 (0.50): F1 = 0.8257\n",
            "  최적 임계값 (0.400): F1 = 0.8398\n",
            "  개선량: +0.0140\n",
            "\n",
            "[추가 메트릭]\n",
            "  ROC-AUC: 0.8904\n",
            "  PR-AUC: 0.9014\n",
            "  평균 Confidence: 0.3046\n",
            "  낮은 Confidence (<0.1): 226개 (13.5%)\n",
            "\n",
            "[혼동행렬 - 최적 임계값]\n",
            "[[555 206]\n",
            " [102 807]]\n",
            "  TN=555, FP=206, FN=102, TP=807\n",
            "  FPR=0.271, FNR=0.112\n",
            "\n",
            "[분류 리포트 - 최적 임계값]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      비활성(0)     0.8447    0.7293    0.7828       761\n",
            "       활성(1)     0.7966    0.8878    0.8398       909\n",
            "\n",
            "    accuracy                         0.8156      1670\n",
            "   macro avg     0.8207    0.8085    0.8113      1670\n",
            "weighted avg     0.8186    0.8156    0.8138      1670\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-38380234.py:245: UserWarning: Glyph 44060 (\\N{HANGUL SYLLABLE GAE}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-38380234.py:246: UserWarning: Glyph 44060 (\\N{HANGUL SYLLABLE GAE}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('threshold_optimization_analysis.png', dpi=300, bbox_inches='tight')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ 시각화 저장: threshold_optimization_analysis.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "[Fold 2]\n",
            "======================================================================\n",
            "피처: 150개 사용\n",
            "학습 데이터: (6679, 150), 검증 데이터: (1670, 150)\n",
            "\n",
            "[성능 비교]\n",
            "  기본 임계값 (0.50): F1 = 0.8084\n",
            "  최적 임계값 (0.420): F1 = 0.8199\n",
            "  개선량: +0.0115\n",
            "\n",
            "[추가 메트릭]\n",
            "  ROC-AUC: 0.8723\n",
            "  PR-AUC: 0.8866\n",
            "  평균 Confidence: 0.3035\n",
            "  낮은 Confidence (<0.1): 225개 (13.5%)\n",
            "\n",
            "[혼동행렬 - 최적 임계값]\n",
            "[[543 218]\n",
            " [126 783]]\n",
            "  TN=543, FP=218, FN=126, TP=783\n",
            "  FPR=0.286, FNR=0.139\n",
            "\n",
            "[분류 리포트 - 최적 임계값]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      비활성(0)     0.8117    0.7135    0.7594       761\n",
            "       활성(1)     0.7822    0.8614    0.8199       909\n",
            "\n",
            "    accuracy                         0.7940      1670\n",
            "   macro avg     0.7969    0.7875    0.7897      1670\n",
            "weighted avg     0.7956    0.7940    0.7923      1670\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "[Fold 3]\n",
            "======================================================================\n",
            "피처: 150개 사용\n",
            "학습 데이터: (6679, 150), 검증 데이터: (1670, 150)\n",
            "\n",
            "[성능 비교]\n",
            "  기본 임계값 (0.50): F1 = 0.7815\n",
            "  최적 임계값 (0.300): F1 = 0.8002\n",
            "  개선량: +0.0187\n",
            "\n",
            "[추가 메트릭]\n",
            "  ROC-AUC: 0.8559\n",
            "  PR-AUC: 0.8669\n",
            "  평균 Confidence: 0.2977\n",
            "  낮은 Confidence (<0.1): 245개 (14.7%)\n",
            "\n",
            "[혼동행렬 - 최적 임계값]\n",
            "[[475 287]\n",
            " [111 797]]\n",
            "  TN=475, FP=287, FN=111, TP=797\n",
            "  FPR=0.377, FNR=0.122\n",
            "\n",
            "[분류 리포트 - 최적 임계값]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      비활성(0)     0.8106    0.6234    0.7047       762\n",
            "       활성(1)     0.7352    0.8778    0.8002       908\n",
            "\n",
            "    accuracy                         0.7617      1670\n",
            "   macro avg     0.7729    0.7506    0.7525      1670\n",
            "weighted avg     0.7696    0.7617    0.7566      1670\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "[Fold 4]\n",
            "======================================================================\n",
            "피처: 150개 사용\n",
            "학습 데이터: (6679, 150), 검증 데이터: (1670, 150)\n",
            "\n",
            "[성능 비교]\n",
            "  기본 임계값 (0.50): F1 = 0.8046\n",
            "  최적 임계값 (0.370): F1 = 0.8244\n",
            "  개선량: +0.0198\n",
            "\n",
            "[추가 메트릭]\n",
            "  ROC-AUC: 0.8808\n",
            "  PR-AUC: 0.8934\n",
            "  평균 Confidence: 0.2982\n",
            "  낮은 Confidence (<0.1): 225개 (13.5%)\n",
            "\n",
            "[혼동행렬 - 최적 임계값]\n",
            "[[515 247]\n",
            " [ 98 810]]\n",
            "  TN=515, FP=247, FN=98, TP=810\n",
            "  FPR=0.324, FNR=0.108\n",
            "\n",
            "[분류 리포트 - 최적 임계값]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      비활성(0)     0.8401    0.6759    0.7491       762\n",
            "       활성(1)     0.7663    0.8921    0.8244       908\n",
            "\n",
            "    accuracy                         0.7934      1670\n",
            "   macro avg     0.8032    0.7840    0.7868      1670\n",
            "weighted avg     0.8000    0.7934    0.7901      1670\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "[Fold 5]\n",
            "======================================================================\n",
            "피처: 150개 사용\n",
            "학습 데이터: (6680, 150), 검증 데이터: (1669, 150)\n",
            "\n",
            "[성능 비교]\n",
            "  기본 임계값 (0.50): F1 = 0.8165\n",
            "  최적 임계값 (0.390): F1 = 0.8287\n",
            "  개선량: +0.0122\n",
            "\n",
            "[추가 메트릭]\n",
            "  ROC-AUC: 0.8887\n",
            "  PR-AUC: 0.8978\n",
            "  평균 Confidence: 0.2973\n",
            "  낮은 Confidence (<0.1): 235개 (14.1%)\n",
            "\n",
            "[혼동행렬 - 최적 임계값]\n",
            "[[541 220]\n",
            " [110 798]]\n",
            "  TN=541, FP=220, FN=110, TP=798\n",
            "  FPR=0.289, FNR=0.121\n",
            "\n",
            "[분류 리포트 - 최적 임계값]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      비활성(0)     0.8310    0.7109    0.7663       761\n",
            "       활성(1)     0.7839    0.8789    0.8287       908\n",
            "\n",
            "    accuracy                         0.8023      1669\n",
            "   macro avg     0.8075    0.7949    0.7975      1669\n",
            "weighted avg     0.8054    0.8023    0.8002      1669\n",
            "\n",
            "\n",
            "======================================================================\n",
            "최종 통계\n",
            "======================================================================\n",
            "\n",
            "[피처 선택 효과]\n",
            "  사용 피처: 150개\n",
            "  제거 피처: 2926개\n",
            "\n",
            "[기본 임계값 (0.5)]\n",
            "  평균 F1: 0.8073\n",
            "  표준편차: 0.0148\n",
            "  Fold별: ['0.8257', '0.8084', '0.7815', '0.8046', '0.8165']\n",
            "\n",
            "[최적화된 임계값]\n",
            "  평균 F1: 0.8226\n",
            "  표준편차: 0.0130\n",
            "  Fold별: ['0.8398', '0.8199', '0.8002', '0.8244', '0.8287']\n",
            "\n",
            "[임계값 통계]\n",
            "  평균 임계값: 0.376\n",
            "  표준편차: 0.041\n",
            "  범위: [0.300, 0.420]\n",
            "  Fold별: ['0.400', '0.420', '0.300', '0.370', '0.390']\n",
            "  변동계수: 0.110\n",
            "  ✓ 임계값이 안정적입니다.\n",
            "\n",
            "[전체 개선량]\n",
            "  F1 개선: +0.0152 (+1.89%)\n",
            "\n",
            "✓ 결과 저장: threshold_optimization_results_v2.csv\n",
            "\n",
            "======================================================================\n",
            "최종 권장 임계값: 0.376\n",
            "이 값을 test 데이터 예측 시 사용하세요.\n",
            "======================================================================\n",
            "\n",
            "✓ 단계 4 완료\n",
            "\n",
            "======================================================================\n",
            "이전 제출 결과 비교 (참고)\n",
            "======================================================================\n",
            "이전 제출:\n",
            "  평균 Confidence: 0.2580\n",
            "  낮은 Confidence (<0.1): 175개 (18.9%)\n",
            "\n",
            "개선 기대:\n",
            "  평균 Confidence: 0.3003\n",
            "  낮은 Confidence (<0.1): 평균 13.8%\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 단계 5: 최종 모델 학습 및 테스트 예측 (개선 버전)\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"단계 5: 최종 모델 학습 및 테스트 예측\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# ============================================================\n",
        "# 5.1 피처 선택 (3단계 결과 활용)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n[5.1] 피처 선택...\")\n",
        "\n",
        "# 특징 중요도 로드\n",
        "importance_df = pd.read_csv('feature_importance_cv.csv')\n",
        "\n",
        "# 상위 150개 피처 선택 (4단계에서 사용한 것과 동일)\n",
        "TOP_N = 150\n",
        "selected_features = importance_df.head(TOP_N)['feature'].tolist()\n",
        "\n",
        "print(f\"  전체 피처: {len(importance_df)}개\")\n",
        "print(f\"  선택된 피처: {len(selected_features)}개\")\n",
        "print(f\"  제거된 피처: {len(importance_df) - len(selected_features)}개\")\n",
        "\n",
        "# 물성 피처 확인\n",
        "desc_cols = ['MolWt', 'clogp', 'sa_score', 'qed']\n",
        "desc_in_selected = [f for f in selected_features if f in desc_cols]\n",
        "print(f\"  물성 피처: {desc_in_selected}\")\n",
        "\n",
        "# ============================================================\n",
        "# 5.2 최적 임계값 로드 (4단계 결과 활용)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n[5.2] 최적 임계값 로드...\")\n",
        "\n",
        "# 4단계 결과 로드\n",
        "threshold_results = pd.read_csv('threshold_optimization_results_v2.csv')\n",
        "optimal_threshold = threshold_results['threshold'].mean()\n",
        "\n",
        "print(f\"  Fold별 임계값: {threshold_results['threshold'].tolist()}\")\n",
        "print(f\"  평균 임계값: {optimal_threshold:.3f}\")\n",
        "print(f\"  표준편차: {threshold_results['threshold'].std():.3f}\")\n",
        "print(f\"  범위: [{threshold_results['threshold'].min():.3f}, {threshold_results['threshold'].max():.3f}]\")\n",
        "\n",
        "# 최종 임계값 결정 (보수적으로 평균값 사용)\n",
        "FINAL_THRESHOLD = optimal_threshold\n",
        "print(f\"\\n  ✓ 최종 사용 임계값: {FINAL_THRESHOLD:.3f}\")\n",
        "\n",
        "# ============================================================\n",
        "# 5.3 전체 학습 데이터로 최종 모델 학습\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n[5.3] 전체 학습 데이터로 최종 모델 학습...\")\n",
        "\n",
        "# 학습 데이터 로드 (선택된 피처만 사용)\n",
        "df_train = pd.read_csv('train.csv')\n",
        "X_train_full = df_train[selected_features]\n",
        "y_train_full = df_train['label'].astype(int)\n",
        "\n",
        "print(f\"  학습 데이터: {X_train_full.shape}\")\n",
        "print(f\"  레이블 분포: {y_train_full.value_counts().to_dict()}\")\n",
        "\n",
        "# 전처리 파이프라인 구성 (선택된 피처 기반)\n",
        "fp_cols_selected = [f for f in selected_features if f.startswith(('ecfp_', 'fcfp_', 'ptfp_'))]\n",
        "desc_cols_selected = [f for f in selected_features if f in desc_cols]\n",
        "\n",
        "preprocessor_final = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('fp', SimpleImputer(strategy='constant', fill_value=0), fp_cols_selected),\n",
        "        ('desc', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), desc_cols_selected)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# 전처리 적용\n",
        "Xt_train_full = preprocessor_final.fit_transform(X_train_full)\n",
        "print(f\"  전처리 후: {Xt_train_full.shape}\")\n",
        "\n",
        "# 최종 모델 학습 (4단계에서 사용한 개선된 하이퍼파라미터)\n",
        "final_model = LGBMClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=7,\n",
        "    num_leaves=31,\n",
        "    min_child_samples=20,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_alpha=1.0,\n",
        "    reg_lambda=1.0,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "final_model.fit(Xt_train_full, y_train_full)\n",
        "print(f\"  ✓ 학습 완료: {Xt_train_full.shape[0]:,}개 샘플\")\n",
        "\n",
        "# ============================================================\n",
        "# 5.4 테스트 데이터 로드 및 전처리\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n[5.4] 테스트 데이터 전처리...\")\n",
        "\n",
        "df_test = pd.read_csv('predict_input.csv')\n",
        "print(f\"  테스트 데이터: {df_test.shape}\")\n",
        "\n",
        "# SMILES 컬럼 저장 (나중에 제출 파일에 사용)\n",
        "test_smiles = df_test['SMILES'].copy()\n",
        "\n",
        "# 선택된 피처만 추출\n",
        "X_test = df_test[selected_features]\n",
        "print(f\"  선택된 피처 추출: {X_test.shape}\")\n",
        "\n",
        "# 전처리 적용 (학습 데이터와 동일한 변환)\n",
        "Xt_test = preprocessor_final.transform(X_test)\n",
        "print(f\"  ✓ 전처리 완료: {Xt_test.shape}\")\n",
        "\n",
        "# ============================================================\n",
        "# 5.5 확률 예측 및 분석\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n[5.5] 확률 예측...\")\n",
        "\n",
        "y_test_proba = final_model.predict_proba(Xt_test)[:, 1]\n",
        "\n",
        "print(f\"  확률 통계:\")\n",
        "print(f\"    평균: {y_test_proba.mean():.4f}\")\n",
        "print(f\"    중앙값: {np.median(y_test_proba):.4f}\")\n",
        "print(f\"    표준편차: {y_test_proba.std():.4f}\")\n",
        "print(f\"    범위: [{y_test_proba.min():.4f}, {y_test_proba.max():.4f}]\")\n",
        "\n",
        "# 확률 분포 확인\n",
        "prob_bins = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "prob_hist, _ = np.histogram(y_test_proba, bins=prob_bins)\n",
        "print(f\"\\n  확률 분포:\")\n",
        "for i in range(len(prob_bins)-1):\n",
        "    count = prob_hist[i]\n",
        "    pct = count / len(y_test_proba) * 100\n",
        "    print(f\"    [{prob_bins[i]:.1f}-{prob_bins[i+1]:.1f}): {count:4d}개 ({pct:5.1f}%)\")\n",
        "\n",
        "# ============================================================\n",
        "# 5.6 최적 임계값 적용 및 예측\n",
        "# ============================================================\n",
        "\n",
        "print(f\"\\n[5.6] 최적 임계값 ({FINAL_THRESHOLD:.3f}) 적용...\")\n",
        "\n",
        "y_test_pred = (y_test_proba >= FINAL_THRESHOLD).astype(int)\n",
        "\n",
        "print(f\"  예측 레이블 분포:\")\n",
        "print(f\"    독성 有(0): {(y_test_pred == 0).sum():4d}개 ({(y_test_pred == 0).sum() / len(y_test_pred) * 100:5.1f}%)\")\n",
        "print(f\"    독성 無(1):   {(y_test_pred == 1).sum():4d}개 ({(y_test_pred == 1).sum() / len(y_test_pred) * 100:5.1f}%)\")\n",
        "\n",
        "# ============================================================\n",
        "# 5.7 Confidence 계산 및 분석\n",
        "# ============================================================\n",
        "\n",
        "print(f\"\\n[5.7] Confidence 분석...\")\n",
        "\n",
        "confidence = np.abs(y_test_proba - 0.5)\n",
        "\n",
        "print(f\"  Confidence 통계:\")\n",
        "print(f\"    평균: {confidence.mean():.4f}\")\n",
        "print(f\"    중앙값: {np.median(confidence):.4f}\")\n",
        "print(f\"    표준편차: {confidence.std():.4f}\")\n",
        "print(f\"    범위: [{confidence.min():.4f}, {confidence.max():.4f}]\")\n",
        "\n",
        "# Confidence 구간별 분포\n",
        "conf_bins = [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "conf_labels = ['매우 낮음 (0.0-0.1)', '낮음 (0.1-0.2)', '보통 (0.2-0.3)',\n",
        "               '높음 (0.3-0.4)', '매우 높음 (0.4-0.5)']\n",
        "\n",
        "print(f\"\\n  Confidence 구간별 분포:\")\n",
        "for i in range(len(conf_bins)-1):\n",
        "    mask = (confidence >= conf_bins[i]) & (confidence < conf_bins[i+1])\n",
        "    count = mask.sum()\n",
        "    pct = count / len(confidence) * 100\n",
        "    print(f\"    {conf_labels[i]}: {count:4d}개 ({pct:5.1f}%)\")\n",
        "\n",
        "# 낮은 Confidence 샘플 식별\n",
        "low_conf_mask = confidence < 0.1\n",
        "low_conf_count = low_conf_mask.sum()\n",
        "low_conf_pct = low_conf_count / len(confidence) * 100\n",
        "\n",
        "print(f\"\\n  낮은 Confidence (<0.1) 샘플:\")\n",
        "print(f\"    개수: {low_conf_count}개 ({low_conf_pct:.1f}%)\")\n",
        "\n",
        "if low_conf_count > 0:\n",
        "    print(f\"    확률 범위: [{y_test_proba[low_conf_mask].min():.4f}, {y_test_proba[low_conf_mask].max():.4f}]\")\n",
        "    print(f\"    평균 확률: {y_test_proba[low_conf_mask].mean():.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# 5.8 제출 파일 생성\n",
        "# ============================================================\n",
        "\n",
        "print(f\"\\n[5.8] 제출 파일 생성...\")\n",
        "\n",
        "# 기본 제출 파일\n",
        "submission_basic = pd.DataFrame({\n",
        "    'SMILES': test_smiles,\n",
        "    'label': y_test_pred\n",
        "})\n",
        "submission_basic.to_csv('submission_final.csv', index=False)\n",
        "print(f\"  ✓ 기본 제출 파일 저장: submission_final.csv\")\n",
        "\n",
        "# 상세 제출 파일 (확률 및 confidence 포함)\n",
        "submission_detailed = pd.DataFrame({\n",
        "    'SMILES': test_smiles,\n",
        "    'label': y_test_pred,\n",
        "    'probability': y_test_proba,\n",
        "    'confidence': confidence\n",
        "})\n",
        "submission_detailed.to_csv('submission_detailed_final.csv', index=False)\n",
        "print(f\"  ✓ 상세 제출 파일 저장: submission_detailed_final.csv\")\n",
        "\n",
        "# 낮은 confidence 샘플만 별도 저장 (추가 검토용)\n",
        "if low_conf_count > 0:\n",
        "    low_conf_samples = submission_detailed[low_conf_mask].copy()\n",
        "    low_conf_samples = low_conf_samples.sort_values('confidence')\n",
        "    low_conf_samples.to_csv('low_confidence_samples.csv', index=False)\n",
        "    print(f\"  ✓ 낮은 confidence 샘플 저장: low_confidence_samples.csv ({low_conf_count}개)\")\n",
        "\n",
        "# ============================================================\n",
        "# 5.9 시각화\n",
        "# ============================================================\n",
        "\n",
        "print(f\"\\n[5.9] 결과 시각화...\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# 1) 확률 분포\n",
        "axes[0, 0].hist(y_test_proba, bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0, 0].axvline(x=FINAL_THRESHOLD, color='r', linestyle='--',\n",
        "                   label=f'Threshold={FINAL_THRESHOLD:.3f}')\n",
        "axes[0, 0].axvline(x=0.5, color='gray', linestyle=':', alpha=0.5, label='Default (0.5)')\n",
        "axes[0, 0].set_xlabel('Probability (Class 1)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].set_title('Test Set Probability Distribution')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2) Confidence 분포\n",
        "axes[0, 1].hist(confidence, bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0, 1].axvline(x=0.1, color='r', linestyle='--',\n",
        "                   label=f'Low Confidence: {low_conf_count}개')\n",
        "axes[0, 1].set_xlabel('Confidence (|prob - 0.5|)')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].set_title('Test Set Confidence Distribution')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3) 레이블 분포\n",
        "label_counts = pd.Series(y_test_pred).value_counts().sort_index()\n",
        "axes[1, 0].bar([0, 1], label_counts.values, color=['#ff7f0e', '#1f77b4'], alpha=0.7)\n",
        "axes[1, 0].set_xticks([0, 1])\n",
        "axes[1, 0].set_xticklabels(['toxic(0)', 'Nontoxic(1)'])\n",
        "axes[1, 0].set_ylabel('Count')\n",
        "axes[1, 0].set_title('Predicted Label Distribution')\n",
        "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
        "for i, v in enumerate(label_counts.values):\n",
        "    axes[1, 0].text(i, v + 10, f'{v}\\n({v/len(y_test_pred)*100:.1f}%)',\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "# 4) 확률 vs Confidence Scatter\n",
        "scatter = axes[1, 1].scatter(y_test_proba, confidence,\n",
        "                             c=y_test_pred, cmap='coolwarm',\n",
        "                             alpha=0.5, s=10)\n",
        "axes[1, 1].axvline(x=FINAL_THRESHOLD, color='r', linestyle='--', alpha=0.7)\n",
        "axes[1, 1].axhline(y=0.1, color='orange', linestyle='--', alpha=0.7)\n",
        "axes[1, 1].set_xlabel('Probability (Class 1)')\n",
        "axes[1, 1].set_ylabel('Confidence')\n",
        "axes[1, 1].set_title('Probability vs Confidence')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "plt.colorbar(scatter, ax=axes[1, 1], label='Predicted Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('test_prediction_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "print(f\"  ✓ 시각화 저장: test_prediction_analysis.png\")\n",
        "\n",
        "# ============================================================\n",
        "# 5.10 최종 요약\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"최종 요약\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\\n[모델 설정]\")\n",
        "print(f\"  선택된 피처: {len(selected_features)}개\")\n",
        "print(f\"  하이퍼파라미터:\")\n",
        "print(f\"    n_estimators: 500\")\n",
        "print(f\"    learning_rate: 0.05\")\n",
        "print(f\"    max_depth: 7\")\n",
        "print(f\"    정규화: L1=1.0, L2=1.0\")\n",
        "\n",
        "print(f\"\\n[임계값]\")\n",
        "print(f\"  최종 임계값: {FINAL_THRESHOLD:.3f}\")\n",
        "print(f\"  (CV 5-Fold 평균, 표준편차: {threshold_results['threshold'].std():.3f})\")\n",
        "\n",
        "print(f\"\\n[테스트 예측]\")\n",
        "print(f\"  전체 샘플: {len(y_test_pred):,}개\")\n",
        "print(f\"  독성 有(0): {(y_test_pred == 0).sum():,}개 ({(y_test_pred == 0).sum() / len(y_test_pred) * 100:.1f}%)\")\n",
        "print(f\"  독성 無(1):   {(y_test_pred == 1).sum():,}개 ({(y_test_pred == 1).sum() / len(y_test_pred) * 100:.1f}%)\")\n",
        "\n",
        "print(f\"\\n[품질 지표]\")\n",
        "print(f\"  평균 Confidence: {confidence.mean():.4f}\")\n",
        "print(f\"  낮은 Confidence (<0.1): {low_conf_count}개 ({low_conf_pct:.1f}%)\")\n",
        "\n",
        "print(f\"\\n[교차검증 성능 (참고)]\")\n",
        "print(f\"  평균 F1: {threshold_results['f1_optimized'].mean():.4f} ± {threshold_results['f1_optimized'].std():.4f}\")\n",
        "print(f\"  평균 ROC-AUC: {threshold_results['roc_auc'].mean():.4f}\")\n",
        "print(f\"  평균 PR-AUC: {threshold_results['pr_auc'].mean():.4f}\")\n",
        "\n",
        "print(f\"\\n[출력 파일]\")\n",
        "print(f\"  ✓ submission_final.csv - 기본 제출 파일\")\n",
        "print(f\"  ✓ submission_detailed_final.csv - 상세 정보 포함\")\n",
        "print(f\"  ✓ test_prediction_analysis.png - 시각화\")\n",
        "if low_conf_count > 0:\n",
        "    print(f\"  ✓ low_confidence_samples.csv - 검토 필요 샘플\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"✓ 단계 5 완료\")\n",
        "print(\"=\" * 70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPLOZQrtDjqU",
        "outputId": "05aa7f35-e189-495b-a7c7-479ad24749f9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "단계 5: 최종 모델 학습 및 테스트 예측\n",
            "======================================================================\n",
            "\n",
            "[5.1] 피처 선택...\n",
            "  전체 피처: 3076개\n",
            "  선택된 피처: 150개\n",
            "  제거된 피처: 2926개\n",
            "  물성 피처: ['clogp', 'sa_score', 'qed', 'MolWt']\n",
            "\n",
            "[5.2] 최적 임계값 로드...\n",
            "  Fold별 임계값: [0.4, 0.42, 0.3, 0.37, 0.39]\n",
            "  평균 임계값: 0.376\n",
            "  표준편차: 0.046\n",
            "  범위: [0.300, 0.420]\n",
            "\n",
            "  ✓ 최종 사용 임계값: 0.376\n",
            "\n",
            "[5.3] 전체 학습 데이터로 최종 모델 학습...\n",
            "  학습 데이터: (8349, 150)\n",
            "  레이블 분포: {1: 4542, 0: 3807}\n",
            "  전처리 후: (8349, 150)\n",
            "  ✓ 학습 완료: 8,349개 샘플\n",
            "\n",
            "[5.4] 테스트 데이터 전처리...\n",
            "  테스트 데이터: (927, 3077)\n",
            "  선택된 피처 추출: (927, 150)\n",
            "  ✓ 전처리 완료: (927, 150)\n",
            "\n",
            "[5.5] 확률 예측...\n",
            "  확률 통계:\n",
            "    평균: 0.5218\n",
            "    중앙값: 0.5213\n",
            "    표준편차: 0.3351\n",
            "    범위: [0.0044, 0.9993]\n",
            "\n",
            "  확률 분포:\n",
            "    [0.0-0.2):  232개 ( 25.0%)\n",
            "    [0.2-0.4):  140개 ( 15.1%)\n",
            "    [0.4-0.6):  133개 ( 14.3%)\n",
            "    [0.6-0.8):  140개 ( 15.1%)\n",
            "    [0.8-1.0):  282개 ( 30.4%)\n",
            "\n",
            "[5.6] 최적 임계값 (0.376) 적용...\n",
            "  예측 레이블 분포:\n",
            "    독성 有(0):  363개 ( 39.2%)\n",
            "    독성 無(1):    564개 ( 60.8%)\n",
            "\n",
            "[5.7] Confidence 분석...\n",
            "  Confidence 통계:\n",
            "    평균: 0.3002\n",
            "    중앙값: 0.3252\n",
            "    표준편차: 0.1504\n",
            "    범위: [0.0002, 0.4993]\n",
            "\n",
            "  Confidence 구간별 분포:\n",
            "    매우 낮음 (0.0-0.1):  133개 ( 14.3%)\n",
            "    낮음 (0.1-0.2):  115개 ( 12.4%)\n",
            "    보통 (0.2-0.3):  165개 ( 17.8%)\n",
            "    높음 (0.3-0.4):  200개 ( 21.6%)\n",
            "    매우 높음 (0.4-0.5):  314개 ( 33.9%)\n",
            "\n",
            "  낮은 Confidence (<0.1) 샘플:\n",
            "    개수: 133개 (14.3%)\n",
            "    확률 범위: [0.4005, 0.6000]\n",
            "    평균 확률: 0.4973\n",
            "\n",
            "[5.8] 제출 파일 생성...\n",
            "  ✓ 기본 제출 파일 저장: submission_final.csv\n",
            "  ✓ 상세 제출 파일 저장: submission_detailed_final.csv\n",
            "  ✓ 낮은 confidence 샘플 저장: low_confidence_samples.csv (133개)\n",
            "\n",
            "[5.9] 결과 시각화...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-2973936078.py:288: UserWarning: Glyph 44060 (\\N{HANGUL SYLLABLE GAE}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2973936078.py:289: UserWarning: Glyph 44060 (\\N{HANGUL SYLLABLE GAE}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('test_prediction_analysis.png', dpi=300, bbox_inches='tight')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✓ 시각화 저장: test_prediction_analysis.png\n",
            "\n",
            "======================================================================\n",
            "최종 요약\n",
            "======================================================================\n",
            "\n",
            "[모델 설정]\n",
            "  선택된 피처: 150개\n",
            "  하이퍼파라미터:\n",
            "    n_estimators: 500\n",
            "    learning_rate: 0.05\n",
            "    max_depth: 7\n",
            "    정규화: L1=1.0, L2=1.0\n",
            "\n",
            "[임계값]\n",
            "  최종 임계값: 0.376\n",
            "  (CV 5-Fold 평균, 표준편차: 0.046)\n",
            "\n",
            "[테스트 예측]\n",
            "  전체 샘플: 927개\n",
            "  독성 有(0): 363개 (39.2%)\n",
            "  독성 無(1):   564개 (60.8%)\n",
            "\n",
            "[품질 지표]\n",
            "  평균 Confidence: 0.3002\n",
            "  낮은 Confidence (<0.1): 133개 (14.3%)\n",
            "\n",
            "[교차검증 성능 (참고)]\n",
            "  평균 F1: 0.8226 ± 0.0145\n",
            "  평균 ROC-AUC: 0.8776\n",
            "  평균 PR-AUC: 0.8892\n",
            "\n",
            "[출력 파일]\n",
            "  ✓ submission_final.csv - 기본 제출 파일\n",
            "  ✓ submission_detailed_final.csv - 상세 정보 포함\n",
            "  ✓ test_prediction_analysis.png - 시각화\n",
            "  ✓ low_confidence_samples.csv - 검토 필요 샘플\n",
            "\n",
            "======================================================================\n",
            "✓ 단계 5 완료\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}